{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27e988b",
   "metadata": {},
   "source": [
    "# SmolVLA Study Guide: How to Learn and Modify the Code\n",
    "\n",
    "This guide will help you understand the core of SmolVLA in LeRobot and show you exactly where to make modifications.\n",
    "\n",
    "## üìö Repository Structure Overview\n",
    "\n",
    "The SmolVLA implementation is located in:\n",
    "```\n",
    "src/lerobot/policies/smolvla/\n",
    "‚îú‚îÄ‚îÄ configuration_smolvla.py    # Configuration (learning rate, batch size, architecture params)\n",
    "‚îú‚îÄ‚îÄ modeling_smolvla.py        # Main model architecture (VLAFlowMatching, SmolVLAPolicy)\n",
    "‚îú‚îÄ‚îÄ smolvlm_with_expert.py    # VLM + Expert architecture implementation\n",
    "‚îî‚îÄ‚îÄ processor_smolvla.py       # Input/output preprocessing\n",
    "```\n",
    "\n",
    "## üéØ Key Files to Study\n",
    "\n",
    "### 1. **Configuration File** (`configuration_smolvla.py`)\n",
    "**Location:** `src/lerobot/policies/smolvla/configuration_smolvla.py`\n",
    "\n",
    "This is where you configure:\n",
    "- **Learning rate and optimizer settings** (lines 76-84)\n",
    "- **Training hyperparameters** (batch size is in `src/lerobot/configs/train.py`)\n",
    "- **Architecture parameters** (VLM layers, expert layers, attention modes)\n",
    "- **Input/output dimensions** (state/action dimensions, image sizes)\n",
    "\n",
    "### 2. **Model Architecture** (`modeling_smolvla.py`)\n",
    "**Location:** `src/lerobot/policies/smolvla/modeling_smolvla.py`\n",
    "\n",
    "Contains:\n",
    "- `SmolVLAPolicy`: Main policy wrapper (line 216)\n",
    "- `VLAFlowMatching`: Core model architecture (line 448)\n",
    "- Forward pass logic\n",
    "- Action prediction logic\n",
    "\n",
    "### 3. **VLM + Expert Architecture** (`smolvlm_with_expert.py`)\n",
    "**Location:** `src/lerobot/policies/smolvla/smolvlm_with_expert.py`\n",
    "\n",
    "Contains:\n",
    "- `SmolVLMWithExpertModel`: The actual neural network architecture (line 61)\n",
    "- Vision encoder, language model, and action expert integration\n",
    "- Attention mechanisms (self-attention vs cross-attention)\n",
    "\n",
    "### 4. **Input/Output Processing** (`processor_smolvla.py`)\n",
    "**Location:** `src/lerobot/policies/smolvla/processor_smolvla.py`\n",
    "\n",
    "Handles:\n",
    "- Image preprocessing\n",
    "- State normalization\n",
    "- Language tokenization\n",
    "- Action denormalization\n",
    "\n",
    "## üîß Where to Modify Key Parameters\n",
    "\n",
    "### **Learning Rate and Optimizer Settings**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/configuration_smolvla.py`\n",
    "\n",
    "**Lines 76-84:**\n",
    "```python\n",
    "optimizer_lr: float = 1e-4                    # ‚Üê Change learning rate here\n",
    "optimizer_betas: tuple[float, float] = (0.9, 0.95)\n",
    "optimizer_eps: float = 1e-8\n",
    "optimizer_weight_decay: float = 1e-10\n",
    "optimizer_grad_clip_norm: float = 10\n",
    "\n",
    "scheduler_warmup_steps: int = 1_000            # ‚Üê Warmup steps\n",
    "scheduler_decay_steps: int = 30_000           # ‚Üê Decay steps\n",
    "scheduler_decay_lr: float = 2.5e-6            # ‚Üê Final learning rate after decay\n",
    "```\n",
    "\n",
    "**How to override via command line:**\n",
    "```bash\n",
    "lerobot-train \\\n",
    "  --policy.type=smolvla \\\n",
    "  --policy.optimizer_lr=2e-4 \\\n",
    "  --policy.scheduler_warmup_steps=2000 \\\n",
    "  --dataset.repo_id=your_dataset\n",
    "```\n",
    "\n",
    "### **Batch Size**\n",
    "\n",
    "**File:** `src/lerobot/configs/train.py`\n",
    "\n",
    "**Line 55:**\n",
    "```python\n",
    "batch_size: int = 8  # ‚Üê Default batch size\n",
    "```\n",
    "\n",
    "**How to override via command line:**\n",
    "```bash\n",
    "lerobot-train \\\n",
    "  --policy.type=smolvla \\\n",
    "  --batch_size=64 \\\n",
    "  --dataset.repo_id=your_dataset\n",
    "```\n",
    "\n",
    "### **Input/Output Dimensions**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/configuration_smolvla.py`\n",
    "\n",
    "**Lines 30-44:**\n",
    "```python\n",
    "n_obs_steps: int = 1              # Number of observation steps\n",
    "chunk_size: int = 50              # Action chunk size\n",
    "n_action_steps: int = 50         # Number of action steps to predict\n",
    "\n",
    "max_state_dim: int = 32          # ‚Üê Maximum state dimension (padded if smaller)\n",
    "max_action_dim: int = 32         # ‚Üê Maximum action dimension (padded if smaller)\n",
    "\n",
    "resize_imgs_with_padding: tuple[int, int] = (512, 512)  # ‚Üê Image size\n",
    "```\n",
    "\n",
    "### **Architecture Modifications**\n",
    "\n",
    "#### **1. VLM Backbone Selection**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/configuration_smolvla.py`\n",
    "\n",
    "**Line 86:**\n",
    "```python\n",
    "vlm_model_name: str = \"HuggingFaceTB/SmolVLM2-500M-Video-Instruct\"  # ‚Üê Change VLM model\n",
    "```\n",
    "\n",
    "#### **2. Number of Layers**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/configuration_smolvla.py`\n",
    "\n",
    "**Lines 97-100:**\n",
    "```python\n",
    "num_expert_layers: int = -1              # ‚Üê Expert layers (-1 = same as VLM)\n",
    "num_vlm_layers: int = 16                 # ‚Üê Number of VLM layers to use\n",
    "self_attn_every_n_layers: int = 2        # ‚Üê Self-attention frequency\n",
    "expert_width_multiplier: float = 0.75     # ‚Üê Expert hidden size multiplier\n",
    "```\n",
    "\n",
    "#### **3. Attention Mode**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/configuration_smolvla.py`\n",
    "\n",
    "**Line 91:**\n",
    "```python\n",
    "attention_mode: str = \"cross_attn\"  # Options: \"cross_attn\" or \"self_attn\"\n",
    "```\n",
    "\n",
    "#### **4. Freezing Components**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/configuration_smolvla.py`\n",
    "\n",
    "**Lines 71-73:**\n",
    "```python\n",
    "freeze_vision_encoder: bool = True    # ‚Üê Freeze vision encoder\n",
    "train_expert_only: bool = True        # ‚Üê Only train expert (not VLM)\n",
    "train_state_proj: bool = True        # ‚Üê Train state projection layer\n",
    "```\n",
    "\n",
    "#### **5. Modify Architecture Components**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/modeling_smolvla.py`\n",
    "\n",
    "**Lines 490-501:** Projection layers\n",
    "```python\n",
    "self.state_proj = nn.Linear(...)        # ‚Üê State projection\n",
    "self.action_in_proj = nn.Linear(...)   # ‚Üê Action input projection\n",
    "self.action_out_proj = nn.Linear(...)  # ‚Üê Action output projection\n",
    "```\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/smolvlm_with_expert.py`\n",
    "\n",
    "**Lines 61-134:** Core architecture\n",
    "- Modify `SmolVLMWithExpertModel.__init__()` to change architecture\n",
    "- Modify `forward()` method (line 404) to change forward pass\n",
    "- Modify attention mechanisms in `forward_attn_layer()` and `forward_cross_attn_layer()`\n",
    "\n",
    "### **Input/Output Processing**\n",
    "\n",
    "**File:** `src/lerobot/policies/smolvla/processor_smolvla.py`\n",
    "\n",
    "**Lines 39-103:** Pre/post-processing pipeline\n",
    "- Modify `make_smolvla_pre_post_processors()` to change preprocessing\n",
    "- Add custom processor steps in the pipeline\n",
    "\n",
    "## üöÄ How to Train with Custom Settings\n",
    "\n",
    "### Example 1: Change Learning Rate and Batch Size\n",
    "\n",
    "```bash\n",
    "lerobot-train \\\n",
    "  --policy.type=smolvla \\\n",
    "  --policy.optimizer_lr=5e-4 \\\n",
    "  --batch_size=32 \\\n",
    "  --dataset.repo_id=your_dataset \\\n",
    "  --steps=100000\n",
    "```\n",
    "\n",
    "### Example 2: Modify Architecture\n",
    "\n",
    "Create a custom config file or override via CLI:\n",
    "\n",
    "```bash\n",
    "lerobot-train \\\n",
    "  --policy.type=smolvla \\\n",
    "  --policy.num_vlm_layers=12 \\\n",
    "  --policy.expert_width_multiplier=0.5 \\\n",
    "  --policy.attention_mode=self_attn \\\n",
    "  --dataset.repo_id=your_dataset\n",
    "```\n",
    "\n",
    "### Example 3: Train from Scratch (No Pretrained Weights)\n",
    "\n",
    "```bash\n",
    "lerobot-train \\\n",
    "  --policy.type=smolvla \\\n",
    "  --policy.load_vlm_weights=False \\\n",
    "  --policy.train_expert_only=False \\\n",
    "  --dataset.repo_id=your_dataset\n",
    "```\n",
    "\n",
    "## üìñ Understanding the Architecture Flow\n",
    "\n",
    "1. **Input Processing** (`processor_smolvla.py`):\n",
    "   - Images ‚Üí Vision encoder embeddings\n",
    "   - State ‚Üí State projection ‚Üí Language embeddings\n",
    "   - Language task ‚Üí Tokenized embeddings\n",
    "\n",
    "2. **Forward Pass** (`modeling_smolvla.py`, `smolvlm_with_expert.py`):\n",
    "   - Vision encoder processes images\n",
    "   - VLM processes vision + language tokens\n",
    "   - Expert processes action tokens with cross-attention to VLM\n",
    "   - Flow matching predicts action sequence\n",
    "\n",
    "3. **Output Processing** (`processor_smolvla.py`):\n",
    "   - Denormalize actions\n",
    "   - Return action chunk\n",
    "\n",
    "## üîç Key Functions to Study\n",
    "\n",
    "### In `modeling_smolvla.py`:\n",
    "- `SmolVLAPolicy._get_action_chunk()` (line 248): How actions are generated\n",
    "- `VLAFlowMatching.forward()` (line 448): Main forward pass\n",
    "- `VLAFlowMatching._forward_flow_matching()`: Flow matching implementation\n",
    "\n",
    "### In `smolvlm_with_expert.py`:\n",
    "- `SmolVLMWithExpertModel.forward()` (line 404): Core architecture forward\n",
    "- `forward_attn_layer()` (line 198): Self-attention mechanism\n",
    "- `forward_cross_attn_layer()` (line 275): Cross-attention mechanism\n",
    "\n",
    "## üìù Training Script Location\n",
    "\n",
    "**File:** `src/lerobot/scripts/lerobot_train.py`\n",
    "\n",
    "This is the main training script. It:\n",
    "- Loads configuration\n",
    "- Creates dataloader\n",
    "- Sets up optimizer/scheduler\n",
    "- Runs training loop\n",
    "\n",
    "## üéì Recommended Learning Path\n",
    "\n",
    "1. **Start with Configuration** (`configuration_smolvla.py`):\n",
    "   - Understand all parameters\n",
    "   - Try changing learning rate and batch size\n",
    "   - Experiment with architecture parameters\n",
    "\n",
    "2. **Study the Architecture** (`smolvlm_with_expert.py`):\n",
    "   - Understand how VLM and expert interact\n",
    "   - Study attention mechanisms\n",
    "   - See how vision, language, and actions are combined\n",
    "\n",
    "3. **Understand Forward Pass** (`modeling_smolvla.py`):\n",
    "   - Trace through `VLAFlowMatching.forward()`\n",
    "   - Understand flow matching\n",
    "   - See how actions are predicted\n",
    "\n",
    "4. **Modify Input/Output** (`processor_smolvla.py`):\n",
    "   - Understand preprocessing pipeline\n",
    "   - Modify normalization\n",
    "   - Add custom processing steps\n",
    "\n",
    "5. **Run Experiments**:\n",
    "   - Start with small changes (learning rate, batch size)\n",
    "   - Progress to architecture modifications\n",
    "   - Use the training script to test changes\n",
    "\n",
    "## üõ†Ô∏è Quick Reference: Common Modifications\n",
    "\n",
    "| What to Change | File | Line(s) | Parameter |\n",
    "|---------------|------|---------|-----------|\n",
    "| Learning Rate | `configuration_smolvla.py` | 76 | `optimizer_lr` |\n",
    "| Batch Size | `configs/train.py` | 55 | `batch_size` |\n",
    "| State Dimension | `configuration_smolvla.py` | 43 | `max_state_dim` |\n",
    "| Action Dimension | `configuration_smolvla.py` | 44 | `max_action_dim` |\n",
    "| Image Size | `configuration_smolvla.py` | 47 | `resize_imgs_with_padding` |\n",
    "| VLM Layers | `configuration_smolvla.py` | 98 | `num_vlm_layers` |\n",
    "| Expert Layers | `configuration_smolvla.py` | 97 | `num_expert_layers` |\n",
    "| Expert Width | `configuration_smolvla.py` | 100 | `expert_width_multiplier` |\n",
    "| Attention Mode | `configuration_smolvla.py` | 91 | `attention_mode` |\n",
    "| VLM Model | `configuration_smolvla.py` | 86 | `vlm_model_name` |\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "- **Documentation:** `docs/source/policy_smolvla_README.md`\n",
    "- **Example Usage:** `examples/tutorial/smolvla/using_smolvla_example.py`\n",
    "- **Training Example:** `examples/training/train_policy.py`\n",
    "- **Paper:** https://arxiv.org/abs/2506.01844\n",
    "\n",
    "## üí° Tips for Experimentation\n",
    "\n",
    "1. **Start Small**: Change one parameter at a time (e.g., just learning rate)\n",
    "2. **Use CLI Overrides**: Test changes without modifying code\n",
    "3. **Check Logs**: Monitor training metrics to see impact of changes\n",
    "4. **Version Control**: Commit before making major changes\n",
    "5. **Read Error Messages**: They often point to the exact line causing issues\n",
    "\n",
    "Happy learning and experimenting! üöÄ\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
